{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UV-Index Wrangling\n",
    "\n",
    "This notebook wrangles the multiple uv-index datasets from 2007-2022 for Adelaide, Brisbane, Canberra, Melbourne, Perth, and Sydney available through the ARAPANSA into a city-specific dataset to be used in the onboarding process of Monash University FIT5120 Onboarding project. The wrangling process assumes that the datasets are saved in the root folder of the project.\n",
    "\n",
    "Data source for each city are as follows:\n",
    "* Melbourne data: https://data.gov.au/dataset/ds-dga-fb836013-f300-4f92-aa1e-fb5014aea40e/details?q=Ultraviolet%20Radiation%20Index\n",
    "* Adelaide data: https://data.gov.au/dataset/ds-dga-026d4974-9efb-403d-9b39-27aee31a6439/details?q=Ultraviolet%20Radiation%20Index\n",
    "* Perth data: https://data.gov.au/dataset/ds-dga-1b55352e-c0d8-48c8-9828-ef12885c9797/details?q=Ultraviolet%20Radiation%20Index\n",
    "* Canberra data: https://data.gov.au/dataset/ds-dga-154d4d3b-2e8d-4dc2-b8ac-8f9805f99826/details?q=Ultraviolet%20Radiation%20Index\n",
    "* Brisbane data: https://data.gov.au/dataset/ds-dga-2a1a2e49-de97-450e-9d0a-482adec68b22/details?q=Ultraviolet%20Radiation%20Index\n",
    "* Sydney data: https://data.gov.au/dataset/ds-dga-c31a759c-a4d4-455f-87a7-98576be14f11/details?q=Ultraviolet%20Radiation%20Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading uv-adelaide-2007.csv\n",
      "Reading uv-adelaide-2008.csv\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non convertible value 2008-01-01 00:01:00 with the unit 's', at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Hima\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslib.pyx:304\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_with_unit_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '2008-01-01 00:01:00'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate-Time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate-Time\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m---> 34\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimestamp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate-Time\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Append the DataFrame to the combined data\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hima\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1050\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1048\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1050\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1051\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[1;32mc:\\Users\\Hima\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:427\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    426\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot specify both format and unit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 427\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_to_datetime_with_unit\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    430\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg must be a string, datetime, list, tuple, 1-d array, or Series\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    431\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Hima\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:539\u001b[0m, in \u001b[0;36m_to_datetime_with_unit\u001b[1;34m(arg, unit, name, utc, errors)\u001b[0m\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    538\u001b[0m         arg \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 539\u001b[0m         arr, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_with_unit_to_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    542\u001b[0m     \u001b[38;5;66;03m# Index constructor _may_ infer to DatetimeIndex\u001b[39;00m\n\u001b[0;32m    543\u001b[0m     result \u001b[38;5;241m=\u001b[39m Index\u001b[38;5;241m.\u001b[39m_with_infer(arr, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\Hima\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslib.pyx:332\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_with_unit_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Hima\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslib.pyx:306\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_with_unit_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: non convertible value 2008-01-01 00:01:00 with the unit 's', at position 0"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# List the cities to be combined\n",
    "cities = ['uv-adelaide','uv-brisbane','uv-melbourne','uv-canberra','uv-perth','uv-sydney']\n",
    "\n",
    "# Create empty dataframe for each city to store the combined data\n",
    "adelaide = pd.DataFrame()\n",
    "brisbane = pd.DataFrame()\n",
    "melbourne = pd.DataFrame()\n",
    "canberra = pd.DataFrame()\n",
    "perth = pd.DataFrame()\n",
    "sydney = pd.DataFrame()\n",
    "\n",
    "# Store the dataframes in a list\n",
    "city_data = [adelaide, brisbane, melbourne, canberra, perth, sydney]\n",
    "\n",
    "# Loop through the files in the root folder\n",
    "for file in os.listdir():\n",
    "    for city_index in range(len(cities)):\n",
    "        # Create an empty DataFrame to store the combined data\n",
    "        combined_data = pd.DataFrame()\n",
    "        if file.endswith('.csv') and file.startswith(cities[city_index]):\n",
    "            # Print the file name\n",
    "            print(f'Reading {file}')\n",
    "\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file)\n",
    "            \n",
    "            # Depending on whether the file contains the 'Date-Time' or 'timestamp' column, convert it to datetime format\n",
    "            if 'Date-Time' in df.columns:\n",
    "                df['Date-Time'] = pd.to_datetime(df['Date-Time'])\n",
    "            elif 'timestamp' in df.columns:\n",
    "                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "                df = df.rename(columns={'timestamp': 'Date-Time'})\n",
    "            \n",
    "            # Append the DataFrame to the combined data\n",
    "            combined_data = pd.concat([combined_data, df], ignore_index=True)\n",
    "        \n",
    "        # Update each city's dataframe with the combined data\n",
    "        city_data[city_index] = combined_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# check if first column is either 'Date-Time' or 'timestamp'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
